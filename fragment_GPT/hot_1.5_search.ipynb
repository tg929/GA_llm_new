{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99bcfb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from utils.chem_utils import get_morgan_fingerprint, is_too_similar_to_children, sentence2mol, get_sa, get_qed\n",
    "import time\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from rdkit import Chem\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from tdc import Oracle\n",
    "import json\n",
    "\n",
    "\n",
    "best_score = -1e8\n",
    "best_smi = None\n",
    "\n",
    "'''\n",
    "改了温度0.8->1.0\n",
    "value_weight = 0\n",
    "fastrollout_weight = 1.0\n",
    "reward中加入max\n",
    "rv放在判断rq和rs后计算\n",
    "只访问可扩展结点\n",
    "\n",
    "init_children = 40\n",
    "c_param = 5\n",
    "n_total_children = 5\n",
    "'''\n",
    "\n",
    "'''\n",
    "v6\n",
    "new_weight\n",
    "'''\n",
    "\n",
    "'''\n",
    "v7\n",
    "init_children = 40\n",
    "c_param = 5\n",
    "n_total_children = 5\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "def oracle_predict(oracle_name, smi):\n",
    "    predictor = Oracle(name=oracle_name)\n",
    "    return predictor(smi)\n",
    "\n",
    "\n",
    "def top_auc(buffer, top_n, freq_log, max_oracle_calls):\n",
    "    sum = 0\n",
    "    prev = 0\n",
    "    called = 0\n",
    "    ordered_results = list(sorted(buffer.items(), key=lambda kv: kv[1][1], reverse=False))\n",
    "    for idx in range(freq_log, min(len(buffer), max_oracle_calls), freq_log):\n",
    "        temp_result = ordered_results[:idx]\n",
    "        temp_result = list(sorted(temp_result, key=lambda kv: kv[1][0], reverse=True))[:top_n]\n",
    "        top_n_now = np.mean([item[1][0] for item in temp_result])\n",
    "        sum += freq_log * (top_n_now + prev) / 2\n",
    "        prev = top_n_now\n",
    "        called = idx\n",
    "    temp_result = list(sorted(ordered_results, key=lambda kv: kv[1][0], reverse=True))[:top_n]\n",
    "    top_n_now = np.mean([item[1][0] for item in temp_result])\n",
    "    sum += (len(buffer) - called) * (top_n_now + prev) / 2\n",
    "    if len(buffer) < max_oracle_calls:\n",
    "        sum += (max_oracle_calls - len(buffer)) * top_n_now\n",
    "    return sum / max_oracle_calls\n",
    "\n",
    "\n",
    "def print_best():\n",
    "    global best_score\n",
    "    global best_smi\n",
    "    print(best_score)\n",
    "    print(best_smi)\n",
    "\n",
    "\n",
    "class MCTSConfig:\n",
    "    # optimization parameters\n",
    "    value_weight = 0  # weight of value in the total reward. 0 means no value.\n",
    "    search_time = 10000  # total search times (equal or larger than than the number of nodes expanded)\n",
    "    min_terminals = -1  # minimum number of terminals must search\n",
    "    max_split_depth = 10  # maximum depth to split the tree. If larger, only single path will be expanded. If -1, no limit. This is a piror knowledge of the problem.\n",
    "    init_children = 40  # initial number of children to expand at the root node. if -1, use N_TOTAL_CHILDREN. This is a piror knowledge of the problem.\n",
    "    n_total_children = 5  # number of children to expand at each node\n",
    "    c_param = 5  # exploration parameter\n",
    "    width_increase_factor = 2  # increase the width of the tree by this factor in Adaptive child allocation\n",
    "\n",
    "    add_value_weight = 0.0\n",
    "    n_simulations = 1\n",
    "    fastrollout_weight = 1.0\n",
    "\n",
    "    greedy_path = False\n",
    "    max_n_repeat = 5\n",
    "    freq_log = 100\n",
    "\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        for k, v in kwargs.items():\n",
    "            setattr(self, k, v)\n",
    "\n",
    "\n",
    "class MolecularProblemState:\n",
    "\n",
    "    def __init__(self,\n",
    "                 model,\n",
    "                 tokenizer,\n",
    "                 predictor,\n",
    "                 cur_molecule=None,  # 当前分子\n",
    "                 cur_step=0,  # 当前步骤\n",
    "                 max_steps=10,  # 最大生成步骤\n",
    "                 is_terminate=False,  # 是否为终止状态\n",
    "                 rewards=None,  # 奖励列表\n",
    "                 has_optimized=False):  # 是否已进行优化\n",
    "        \"\"\"\n",
    "        初始化分子问题状态，用于分子生成或优化任务。\n",
    "        \"\"\"\n",
    "        self.predictor = predictor\n",
    "        self.cur_molecule = cur_molecule\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        sentence = self.tokenizer.decode(self.cur_molecule[0])\n",
    "        self.cur_sentence = sentence\n",
    "        self.cur_step = cur_step\n",
    "        self.max_steps = max_steps\n",
    "        self.is_terminate = is_terminate\n",
    "        self.rewards = rewards if rewards is not None else []\n",
    "        self.has_optimized = has_optimized\n",
    "\n",
    "    def get_cur_molecule(self):\n",
    "        return self.cur_molecule\n",
    "\n",
    "    def get_cur_step(self):\n",
    "        return self.cur_step\n",
    "\n",
    "    def is_terminal(self):\n",
    "        \"\"\"\n",
    "        判断是否终止：\n",
    "          - 如果已经检测到SMILES (或其他判定条件) 则终止\n",
    "          - 或者已经达到最大生成步数\n",
    "          - 或者 is_terminate 被手动置为 True\n",
    "        \"\"\"\n",
    "        has_eos = self.check_eos_exist()\n",
    "        max_lines_reached = self.cur_step >= self.max_steps\n",
    "        return has_eos or max_lines_reached or self.is_terminate\n",
    "\n",
    "    def check_eos_exist(self):\n",
    "        \"\"\"\n",
    "        检测当前输出中是否已经出现了 SMILES 标记或其他判定条件\n",
    "        这里以简单的正则或关键字 \"SMILES:\" 判断为例。\n",
    "        \"\"\"\n",
    "        # 示例：用来匹配类似 “SMILES: C1=CC=CC=C1” 这样的字符串\n",
    "        if \"[EOS]\" in self.cur_sentence:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_smiles(completion):\n",
    "        \"\"\"\n",
    "        从文本中提取 SMILES。\n",
    "        如果未能匹配到，则返回 INVALID_ANS。\n",
    "        \"\"\"\n",
    "        SMILES_RE = re.compile(r\"(?:SMILES:\\s*)([A-Za-z0-9@+\\-\\[\\]\\(\\)=#$%]+)\")\n",
    "        match = SMILES_RE.search(completion)\n",
    "        if match:\n",
    "            return match.group(1).strip()\n",
    "        else:\n",
    "            return \"<INVALID_SMILES>\"\n",
    "\n",
    "    def is_correct(self):\n",
    "        \"\"\"\n",
    "        若存在参考 SMILES (self.answer)，可在此做简单比较/校验。\n",
    "        例如：\n",
    "        1. 直接字符串对比\n",
    "        2. 或者使用 RDKit 等工具对分子做同一性判断（需要另行安装与配置）\n",
    "        \"\"\"\n",
    "        predicted_smiles = self.extract_smiles(self.cur_molecule)\n",
    "        if predicted_smiles == \"<INVALID_SMILES>\":\n",
    "            return False\n",
    "        # 简单示例：直接字符串比较\n",
    "        return predicted_smiles\n",
    "\n",
    "    def get_value(self):\n",
    "        \"\"\"\n",
    "        计算分子性质得分 (示例：使用RDKit的QED作为分子打分)。\n",
    "        如果SMILES非法，则返回负分以示惩罚。\n",
    "        \"\"\"\n",
    "        _, smiles = sentence2mol(self.cur_sentence)\n",
    "        value = self.get_reward(smiles)\n",
    "        return value\n",
    "\n",
    "    def get_reward(self, smiles):\n",
    "        if smiles is None:\n",
    "            return -1.0\n",
    "\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            return -1.0\n",
    "\n",
    "        reward = oracle_predict(self.predictor, smiles)\n",
    "        if not isinstance(reward, float):\n",
    "            a = 1\n",
    "        return reward\n",
    "\n",
    "    def cond_actions(self, to_end=False, is_greedy=False):\n",
    "        \"\"\"\n",
    "        执行一次“只生成一步”的动作。\n",
    "        可设置 is_greedy=True 做贪心解码等。\n",
    "        \"\"\"\n",
    "        # 这里简化，不区分 simulation / real\n",
    "        # 如果要区分，可以再添加参数\n",
    "        n_attempts = 5\n",
    "        for attempt in range(n_attempts):\n",
    "            try:\n",
    "                if to_end:\n",
    "                    action, smiles_answer, has_end_token = self.action2end(is_greedy=is_greedy)  # 返回的是token对应idx的列表\n",
    "                else:\n",
    "                    action, smiles_answer, has_end_token = self.actions(is_greedy=is_greedy)\n",
    "                    if len(action) == 0:\n",
    "                        continue\n",
    "                return action, smiles_answer, has_end_token\n",
    "            except Exception as e:\n",
    "                if attempt < n_attempts - 1:\n",
    "                    print(f'Retry {attempt}, error: {type(e).__name__}', flush=True)\n",
    "                    continue\n",
    "                else:\n",
    "                    raise e\n",
    "\n",
    "    def actions(self, is_greedy=False):\n",
    "        \"\"\"\n",
    "        只做一次推断调用，使用你自己的generate函数。\n",
    "        \"\"\"\n",
    "        temperature = 0.0 if is_greedy else 1.5\n",
    "        # 假设你自己实现了一个 my_generate 函数，可以直接调用\n",
    "        action, smiles_answer, has_end_token = self.generate_fragment(\n",
    "            cur_molecule=self.cur_molecule,\n",
    "            max_seq_len=1024,\n",
    "            temperature=temperature,\n",
    "            top_k=None,\n",
    "            stream=False,\n",
    "            rp=1.0,\n",
    "            kv_cache=True,\n",
    "            is_simulation=False\n",
    "        )\n",
    "        return action, smiles_answer, has_end_token\n",
    "\n",
    "    def take_action(self, action):\n",
    "        \"\"\"\n",
    "        将生成的新文本拼接到 cur_molecule 中，更新状态。\n",
    "        \"\"\"\n",
    "        new_answer = torch.as_tensor(action, dtype=self.cur_molecule.dtype, device=self.cur_molecule.device).unsqueeze(\n",
    "            0)\n",
    "        next_state = MolecularProblemState(\n",
    "            model=self.model,\n",
    "            tokenizer=self.tokenizer,\n",
    "            predictor=self.predictor,\n",
    "            cur_molecule=new_answer,\n",
    "            cur_step=self.cur_step + 1,\n",
    "            max_steps=self.max_steps,\n",
    "            is_terminate=False  # 后面会根据 is_terminal 判定\n",
    "        )\n",
    "        return next_state\n",
    "\n",
    "    def action2end(self, is_greedy):\n",
    "        \"\"\"\n",
    "        一次性生成到结束。\n",
    "        \"\"\"\n",
    "        temperature = 0.0 if is_greedy else 1.5\n",
    "        action, smiles_answer, has_end_token = self.generate_fragment(\n",
    "            cur_molecule=self.cur_molecule,\n",
    "            max_seq_len=1024,\n",
    "            temperature=temperature,\n",
    "            top_k=None,\n",
    "            stream=False,\n",
    "            rp=1.0,\n",
    "            kv_cache=True,\n",
    "            is_simulation=True\n",
    "        )\n",
    "\n",
    "        return action, smiles_answer, has_end_token\n",
    "\n",
    "    def take_action_end(self, is_greedy=False):\n",
    "        assert is_greedy == False\n",
    "        \"\"\"\n",
    "        一次性生成到结束版本，适用于分子GPT场景。\n",
    "        \"\"\"\n",
    "        # 如果已经终止，就直接返回当前状态即可\n",
    "        if self.is_terminal():\n",
    "            return self\n",
    "\n",
    "        # 多次重试，若真的都失败了就抛异常\n",
    "        n_attempts = 20  # 可自定义\n",
    "        final_action = \"\"\n",
    "        for attempt in range(n_attempts):\n",
    "            try:\n",
    "                final_action, smiles_answer, has_end_token = self.action2end(is_greedy=is_greedy)\n",
    "                break\n",
    "            except Exception as e:\n",
    "                if attempt < n_attempts - 1:\n",
    "                    print(f\"[take_action_end] attempt {attempt}, error: {type(e).__name__}. Retrying...\")\n",
    "                    continue\n",
    "                else:\n",
    "                    print(f\"[take_action_end] All attempts failed. Error: {type(e).__name__}\")\n",
    "                    raise e\n",
    "\n",
    "        # 计算生成的步骤数，如无需分行可直接视为 1 步\n",
    "        # 或者如果你的 final_action 有换行，可以按换行 split\n",
    "        # 这里示例用 .split('\\n')\n",
    "        n_steps = smiles_answer.count('[SEP]')\n",
    "\n",
    "        # 拼接到现有答案\n",
    "        answer_updated = torch.as_tensor(final_action, dtype=self.cur_molecule.dtype,\n",
    "                                         device=self.cur_molecule.device).unsqueeze(0)\n",
    "        # 构造一个新的 ProblemState，标记 is_terminate=True\n",
    "        end_state = MolecularProblemState(\n",
    "            model=self.model,\n",
    "            tokenizer=self.tokenizer,\n",
    "            predictor=self.predictor,\n",
    "            cur_molecule=answer_updated,\n",
    "            cur_step=self.cur_step + n_steps,\n",
    "            max_steps=1000,  # 或者任意大值\n",
    "            is_terminate=True\n",
    "        )\n",
    "        return end_state\n",
    "\n",
    "    def generate_fragment(self, cur_molecule, max_seq_len, temperature, top_k, stream, rp, kv_cache, is_simulation):\n",
    "        with torch.no_grad():\n",
    "            res_y = self.model.generate(cur_molecule, self.tokenizer, max_new_tokens=max_seq_len,\n",
    "                                        temperature=temperature, top_k=top_k, stream=stream, rp=rp, kv_cache=kv_cache,\n",
    "                                        is_simulation=is_simulation)\n",
    "            # print('[A]: ', end='')\n",
    "            try:\n",
    "                y = next(res_y)\n",
    "            except StopIteration:\n",
    "                print(\"No answer\")\n",
    "\n",
    "            history_idx = 0\n",
    "            complete_answer = cur_molecule[0].tolist()  # 用于保存整个生成的句子\n",
    "\n",
    "            while y != None:\n",
    "                answer = y[0].tolist()\n",
    "                # 保存生成的片段到完整回答中\n",
    "                complete_answer += answer[history_idx:]\n",
    "\n",
    "                try:\n",
    "                    y = next(res_y)\n",
    "                except:\n",
    "                    break\n",
    "                history_idx = len(answer)\n",
    "                if not stream:\n",
    "                    break\n",
    "\n",
    "        smiles_answer = self.tokenizer.decode(complete_answer)\n",
    "        # print(smiles_answer, flush=True)\n",
    "        has_end_token = False\n",
    "        if \"[EOS]\" in smiles_answer:\n",
    "            has_end_token = True\n",
    "\n",
    "        return complete_answer, smiles_answer, has_end_token\n",
    "\n",
    "\n",
    "class MonteCarloTreeSearchNode:\n",
    "    \"\"\"\n",
    "    适配为分子GPT场景的 MCTS Node。\n",
    "    如果你还有外部打分、相似度过滤等逻辑，可以保留并在里面写对 SMILES 的判断。\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 state,\n",
    "                 config,\n",
    "                 parent=None,\n",
    "                 parent_action=None,\n",
    "                 depth=0,\n",
    "                 node_id=None,\n",
    "                 n_repeat_by_parent=1):\n",
    "\n",
    "        self.config = config\n",
    "\n",
    "        # 基本节点属性\n",
    "        self.state = state\n",
    "        self.parent = parent\n",
    "        self.parent_action = parent_action  # 该节点是由什么 action 从父节点扩展来的\n",
    "        self.children = []\n",
    "        self._number_of_visits = 0  # 访问次数\n",
    "        self._results = []  # 回传的奖励(或评分)累加，用于计算 Q 值\n",
    "\n",
    "        # Molecule GPT 可能需要额外的数据结构，这里仅示例\n",
    "        self._values = []  # 如果有对分子序列的价值预测，可放这\n",
    "        self._cached_reward = 0.  # 缓存某一次最终reward（可选）\n",
    "\n",
    "        # 节点搜索超参\n",
    "        self.depth = depth\n",
    "        self.node_id = node_id\n",
    "        self.n_repeat_by_parent = n_repeat_by_parent\n",
    "        self.n_repeat = 0\n",
    "        # 用于限制最大深度，或动态扩展子节点个数\n",
    "        if self.config.max_split_depth < 0:\n",
    "            # 如果是 -1，代表不限制\n",
    "            self.config.max_split_depth = self.depth\n",
    "        if self.depth == 0:\n",
    "            self.n_total_children_adaptive = self.config.init_children if self.config.init_children > -1 else self.config.init_children\n",
    "        elif self.depth > self.config.max_split_depth:\n",
    "            self.n_total_children_adaptive = 1\n",
    "        else:\n",
    "            self.n_total_children_adaptive = self.config.n_total_children\n",
    "\n",
    "        # 可以做一些自适应扩展或剪枝相关的变量\n",
    "        self.max_q_diff = 0\n",
    "        self.expandable = True\n",
    "\n",
    "    def n(self):\n",
    "        \"\"\"访问次数。\"\"\"\n",
    "        return self._number_of_visits\n",
    "\n",
    "    def q(self):\n",
    "        \"\"\"累加的 Q 值，可简单用 sum(_results)。\"\"\"\n",
    "        return np.sum(self._results)\n",
    "\n",
    "    def result(self):\n",
    "        \"\"\"results列表\"\"\"\n",
    "        return self._results\n",
    "\n",
    "    def is_terminal_node(self):\n",
    "        \"\"\"判断状态是否已经结束（比如已经生成了完整 SMILES）。\"\"\"\n",
    "        return self.state.is_terminal()\n",
    "\n",
    "    def is_fully_expanded(self):\n",
    "        \"\"\"是否已经有足够的子节点，不再继续扩展。\"\"\"\n",
    "        return len(self.children) >= self.n_total_children_adaptive\n",
    "\n",
    "    def n_children(self):\n",
    "        return len(self.children)\n",
    "\n",
    "    def total_number_nodes(self):\n",
    "        \"\"\"计算以本节点为根的所有节点数。\"\"\"\n",
    "        tot_node = 1\n",
    "        for child in self.children:\n",
    "            tot_node += child.total_number_nodes()\n",
    "        return tot_node\n",
    "\n",
    "    def get_ancestor_child_indices(self):\n",
    "        indices = []\n",
    "        current_node = self\n",
    "        while current_node.parent is not None:\n",
    "            index = current_node.parent.children.index(current_node)\n",
    "            indices.append(index)\n",
    "            current_node = current_node.parent\n",
    "        return indices[::-1]\n",
    "\n",
    "    def retrieve_origin_value(self):\n",
    "        \"\"\"如果有某个子节点对应的初始价值，可在此返回。\"\"\"\n",
    "        return self._values[0] if len(self._values) > 0 else None\n",
    "\n",
    "    def set_cached_reward(self, raw_value):\n",
    "        self._cached_reward = raw_value\n",
    "\n",
    "    def get_cached_reward(self):\n",
    "        return self._cached_reward\n",
    "\n",
    "    def expand(self):\n",
    "        \"\"\"\n",
    "        选出一个可接受的新 action（即新的 SMILES 片段或下一步 Token），\n",
    "        创建新的子节点并返回。\n",
    "        \"\"\"\n",
    "        action, has_end_token, n_repeat = self.get_acceptable_action()\n",
    "        self.n_repeat = n_repeat\n",
    "\n",
    "        # 调用 ProblemState 的 take_action，将该 action 拼接到当前 SMILES/文本中，得到新状态\n",
    "        next_state = self.state.take_action(action)\n",
    "\n",
    "        # 构造新的子节点\n",
    "        cur_n_children = len(self.children)\n",
    "        cur_node_id = self.node_id\n",
    "        child_node = MonteCarloTreeSearchNode(\n",
    "            state=next_state,\n",
    "            config=self.config,\n",
    "            parent=self,\n",
    "            parent_action=action,\n",
    "            depth=self.depth + 1,\n",
    "            node_id=f\"{cur_node_id}-{cur_n_children}\" if cur_node_id else None,\n",
    "            n_repeat_by_parent=n_repeat\n",
    "        )\n",
    "\n",
    "        self.children.append(child_node)\n",
    "        return child_node\n",
    "\n",
    "    def get_acceptable_action(self):\n",
    "        \"\"\"\n",
    "        核心函数：获取一个“合适的 action”。\n",
    "        - 可以做相似度过滤\n",
    "        - 可以检测 SMILES 是否已出现\n",
    "        - 等等...\n",
    "        \"\"\"\n",
    "        # 先收集本节点现有子节点的指纹\n",
    "        children_fps = []\n",
    "        for child in self.children:\n",
    "            # 假设 child.parent_action 保存着其对应 SMILES\n",
    "            child_mol, child_smiles = sentence2mol(child.state.cur_sentence)\n",
    "            fp = get_morgan_fingerprint(child_mol)\n",
    "            if fp is not None:\n",
    "                children_fps.append(fp)\n",
    "        n_repeat = 0\n",
    "\n",
    "        # 到达最大深度，就一次性生成到结束\n",
    "        to_end = self.config.max_split_depth <= (self.depth + 1)\n",
    "        # 若本层还没扩展开任何子节点，且是 greedy path，可以设置 is_greedy=True\n",
    "        is_greedy = self.config.greedy_path and len(self.children) == 0\n",
    "        # 如果希望避免第一层 action 是空的\n",
    "        # avoid_empty = self.depth == 0\n",
    "\n",
    "        # 在这里实现一个循环重试，以保证得到一个“相似度较低”的 SMILES\n",
    "        while True:\n",
    "            action, smiles_answer, has_end_token = self.state.cond_actions(\n",
    "                to_end=to_end,\n",
    "                is_greedy=is_greedy,\n",
    "            )\n",
    "\n",
    "            new_mol, _ = sentence2mol(smiles_answer)\n",
    "            # 计算 new_smiles 的指纹\n",
    "            new_fp = get_morgan_fingerprint(new_mol)\n",
    "            if new_fp is None:\n",
    "                # 如果连分子都解析不了，可以视需求来决定怎么处理：\n",
    "                # - 直接重试\n",
    "                # - 当作已达终点\n",
    "                # - 或者接受该结果\n",
    "                n_repeat += 1\n",
    "                if n_repeat >= self.config.max_n_repeat:\n",
    "                    # 超过重试上限就返回这个action\n",
    "                    break\n",
    "                continue\n",
    "\n",
    "            # 计算与现有子节点的相似度，如果都在阈值以下，则接受\n",
    "            if not is_too_similar_to_children(new_fp, children_fps, threshold=0.8):\n",
    "                # 找到一个不相似的 SMILES\n",
    "                break\n",
    "            else:\n",
    "                n_repeat += 1\n",
    "                # 若超过重试上限，就直接返回这次的 action（或可改为其它处理）\n",
    "                if n_repeat >= self.config.max_n_repeat:\n",
    "                    break\n",
    "\n",
    "        return action, has_end_token, n_repeat\n",
    "\n",
    "    def can_expand(self):\n",
    "        \"\"\"判断当前节点自身是否可扩展（生成新的子节点）\"\"\"\n",
    "        return not self.is_terminal_node() and not self.is_fully_expanded()\n",
    "\n",
    "    def has_expandable_descendant(self):\n",
    "        \"\"\"递归检查当前节点或其子孙节点是否可扩展\"\"\"\n",
    "        if not self.expandable:\n",
    "            return False\n",
    "        # 如果当前节点自身可扩展，直接返回 True\n",
    "        if self.can_expand():\n",
    "            return True\n",
    "        # 递归检查所有子节点\n",
    "        for child in self.children:\n",
    "            if child.has_expandable_descendant():\n",
    "                return True\n",
    "        # 所有子孙节点均不可扩展\n",
    "        self.expandable = False\n",
    "        return False\n",
    "\n",
    "    def best_child(self, alpha=1):\n",
    "        \"\"\"\n",
    "        改进的 best_child 逻辑：\n",
    "        1. 过滤掉没有可扩展后代的子节点\n",
    "        2. 在剩余子节点中选择 UCT 值最高的\n",
    "        \"\"\"\n",
    "        valid_children = []\n",
    "        for child in self.children:\n",
    "            # 只保留有可扩展后代的子节点\n",
    "            if child.has_expandable_descendant():\n",
    "                valid_children.append(child)\n",
    "\n",
    "        # 如果没有有效子节点，返回 None\n",
    "        if not valid_children:\n",
    "            return None\n",
    "\n",
    "        # 计算有效子节点的 UCT 值\n",
    "        choices_weights = []\n",
    "        for c in valid_children:\n",
    "            exploit = alpha * c.q() / c.n() + (1 - alpha) * max(c.result())\n",
    "            explore = np.sqrt(np.log(self.n()) / c.n())\n",
    "            uct_value = exploit + self.config.c_param * explore\n",
    "            choices_weights.append(uct_value)\n",
    "\n",
    "        # 选择 UCT 值最高的子节点\n",
    "        idx = np.argmax(choices_weights)\n",
    "        return valid_children[idx]\n",
    "\n",
    "    def backpropagate(self, value):\n",
    "        \"\"\"\n",
    "        回溯更新：在本节点累加 result，并递归更新父节点。\n",
    "        \"\"\"\n",
    "        self._number_of_visits += 1\n",
    "        self._results.append(value)\n",
    "        if self.parent:\n",
    "            self.parent.backpropagate(value)\n",
    "\n",
    "    def _tree_policy(self):\n",
    "        \"\"\"\n",
    "        Select and expand\n",
    "        Selection strategy: if not fully expanded, pick current node, otherwise pick best child and check\n",
    "        MCTS 核心：迭代策略\n",
    "          1. 向下选择(Selection)\n",
    "          2. 扩展(Expansion)\n",
    "        \"\"\"\n",
    "        current_node = self\n",
    "        while not current_node.is_terminal_node():  # 只要不是终止结点，就已知向下搜索\n",
    "            current_node.update_n_total_children(\n",
    "                self.config.width_increase_factor)  # 根据子节点的情况自适应地增加/减少 n_total_children_adaptive\n",
    "            if not current_node.is_fully_expanded():  # 如果当前结点还能继续扩展，就继续扩展\n",
    "                # 扩展一个新的子节点\n",
    "                return current_node.expand(), True\n",
    "            else:\n",
    "                current_node = current_node.best_child()  # 如果当前结点不能继续扩展，就找它的孩子结点\n",
    "                if current_node is None:\n",
    "                    return self, False\n",
    "        return current_node, False\n",
    "\n",
    "    def add_value(self, is_additional=False):\n",
    "        \"\"\"\n",
    "        用于对当前分子进行一次“价值评估”，如 QED、LogP 或其他性质。\n",
    "        如果 is_additional=True，可表示评估另一种性质（比如毒性评分）。\n",
    "        \"\"\"\n",
    "        raw_value = self.state.get_value()\n",
    "\n",
    "        # 如果需要，你也可以对 raw_value 做归一化或缩放，如：\n",
    "        # raw_value = (raw_value - 0.5) * 2  # 将 [0,1] 区间映射到 [-1,1] 之类\n",
    "        return raw_value\n",
    "\n",
    "    def add_simulate(self):\n",
    "        \"\"\"\n",
    "        做一个“快速模拟/评估”。\n",
    "        在分子GPT场景下，可以:\n",
    "          1. 随机在当前分子基础上扩展几步\n",
    "          2. 计算每次得到的分子打分\n",
    "          3. 取平均或其他统计值\n",
    "        这样让节点在还未真正完全展开时，就对可能的后续做一个估计，用于指导MCTS。\n",
    "        \"\"\"\n",
    "        value = self.fast_rollout_evaluation()\n",
    "\n",
    "        # 此处示例返回平均值\n",
    "        return value\n",
    "\n",
    "    def fast_rollout_evaluation(self):\n",
    "        \"\"\"\n",
    "        Fast-rollout and return mean value from ORM.\n",
    "        \"\"\"\n",
    "\n",
    "        action, smiles_answer, has_end_token = self.state.generate_fragment(\n",
    "            cur_molecule=self.state.cur_molecule,\n",
    "            max_seq_len=1024,\n",
    "            temperature=1.5,\n",
    "            top_k=None,\n",
    "            stream=False,\n",
    "            rp=1.0,\n",
    "            kv_cache=True,\n",
    "            is_simulation=True\n",
    "        )\n",
    "        _, smiles = sentence2mol(smiles_answer)\n",
    "        value = self.state.get_reward(smiles)\n",
    "\n",
    "        return value\n",
    "\n",
    "    def update_n_total_children(self, increase_factor):\n",
    "        \"\"\"\n",
    "        如果想根据子节点的情况自适应地增加/减少 n_total_children_adaptive，\n",
    "        可以在这里自定义逻辑。\n",
    "        \"\"\"\n",
    "        if not self.children:\n",
    "            return\n",
    "        # 简单示例：以子节点平均价值为参考做一些扩展\n",
    "        values = [np.sum(child.q()) / child.n() for child in self.children]\n",
    "        values = np.array(values)\n",
    "        mean_value = np.mean(values)\n",
    "        diff_values = np.abs(values - mean_value)\n",
    "        value_diff = np.max(diff_values)\n",
    "        if value_diff > self.max_q_diff:\n",
    "            self.max_q_diff = value_diff\n",
    "\n",
    "        new_n_total_children = min(int(increase_factor * value_diff), 10)\n",
    "        if new_n_total_children > self.n_total_children_adaptive:\n",
    "            self.n_total_children_adaptive = new_n_total_children\n",
    "\n",
    "        # 若还有别的规则，比如重复次数、方差判断等，也可以在这里加\n",
    "\n",
    "    def best_action_global_leaf(self):\n",
    "        \"\"\"\n",
    "        找到整棵子树中自身最大单次 reward 值最高的叶子节点。\n",
    "        \"\"\"\n",
    "        if self.is_terminal_node():\n",
    "            return self  # 自己就是叶子\n",
    "\n",
    "        best_leaf = None\n",
    "        highest_reward = float('-inf')\n",
    "\n",
    "        for child in self.children:\n",
    "            leaf = child.best_action_global_leaf()  # 递归查找子树\n",
    "            if leaf is None:\n",
    "                continue  # 忽略非终止节点或无效子树\n",
    "            current_reward = max(leaf.result()) if leaf.result() else 0  # 取该叶子节点的最大单次 reward\n",
    "\n",
    "            if current_reward > highest_reward:\n",
    "                highest_reward = current_reward\n",
    "                best_leaf = leaf\n",
    "\n",
    "        return best_leaf\n",
    "\n",
    "    def best_child_greedy(self):\n",
    "        \"\"\"\n",
    "        简单的贪心策略(不加探索项)。\n",
    "        \"\"\"\n",
    "        if not self.children:\n",
    "            return None\n",
    "        choices = [c.q() / c.n() if c.n() > 0 else 0 for c in self.children]\n",
    "        idx = np.argmax(choices)\n",
    "        return self.children[idx]\n",
    "\n",
    "    def best_action_greedy_leaf(self):\n",
    "        \"\"\"\n",
    "        递归找到底层节点(贪心)。\n",
    "        \"\"\"\n",
    "        current_node = self\n",
    "        while not current_node.is_terminal_node():\n",
    "            next_node = current_node.best_child_greedy()\n",
    "            if next_node is None:\n",
    "                break\n",
    "            current_node = next_node\n",
    "        return current_node\n",
    "\n",
    "    def get_end_state(self):\n",
    "        \"\"\"\n",
    "        如果需要“一次性生成到结束”，可以在 state 中写好 take_action_end。\n",
    "        \"\"\"\n",
    "        end_state = self.state.take_action_end(is_greedy=False)\n",
    "        return end_state\n",
    "\n",
    "    # 一些用于调试或收集信息的辅助方法：\n",
    "    def generate_all_paths(self):\n",
    "        \"\"\"\n",
    "        从当前节点遍历所有子树，把路径都返回。\n",
    "        \"\"\"\n",
    "        all_paths = []\n",
    "        all_path_set = set()\n",
    "        queue = deque(self.children)\n",
    "        while queue:\n",
    "            cur = queue.popleft()\n",
    "            cur_path = cur.state.cur_molecule\n",
    "            if cur_path in all_path_set:\n",
    "                continue\n",
    "            all_paths.append({\n",
    "                \"path\": cur_path,\n",
    "                \"depth\": cur.depth,\n",
    "                \"score\": cur.get_cached_reward(),\n",
    "                \"is_terminal\": cur.is_terminal_node()\n",
    "            })\n",
    "            all_path_set.add(cur_path)\n",
    "            queue.extend(cur.children)\n",
    "        return all_paths\n",
    "\n",
    "    def get_all_leaves(self):\n",
    "        \"\"\"获取所有叶节点。\"\"\"\n",
    "        if not self.children:\n",
    "            return [self]\n",
    "        leaves = []\n",
    "        for child in self.children:\n",
    "            leaves.extend(child.get_all_leaves())\n",
    "        return leaves\n",
    "\n",
    "\n",
    "class MCTS:\n",
    "    def __init__(self, initial_state, config, args=None):\n",
    "        \"\"\"\n",
    "        initial_state:  初始 ProblemState，包含生成分子GPT的上下文等\n",
    "        config:         包含各类超参的字典，如搜索时间、c_param 等\n",
    "        args:           可能带有命令行参数等\n",
    "        \"\"\"\n",
    "        self.initial_state = initial_state\n",
    "\n",
    "        self.config = config\n",
    "        self.args = args\n",
    "\n",
    "        self.root = None\n",
    "        self.max_search_depth = 0\n",
    "        self.unique_nodes = set()\n",
    "        self.time_taken = 0\n",
    "\n",
    "    def run_mcts(self):\n",
    "        \"\"\"\n",
    "        MCTS 主循环：Selection / Expansion / Evaluation / Backpropagation\n",
    "        \"\"\"\n",
    "        # 创建根节点\n",
    "        if self.root is None:\n",
    "            self.root = MonteCarloTreeSearchNode(state=self.initial_state,\n",
    "                                                 config=self.config,\n",
    "                                                 depth=0,\n",
    "                                                 node_id='root')\n",
    "\n",
    "        search_iter = 0\n",
    "        n_terminals = 0\n",
    "\n",
    "        n_steps, n_rollouts, n_requests = 0, 0, 0\n",
    "\n",
    "        # 执行蒙特卡洛树搜索\n",
    "        pbar = tqdm(range(self.config.search_time),\n",
    "                    desc=\"MCTS simulations\",\n",
    "                    leave=True)\n",
    "        # 初始化记录变量\n",
    "        buffer = {}\n",
    "        unvalid = 0\n",
    "        # 继续搜索，直到达到给定的时间次数 或者找到足够多终止节点\n",
    "        while search_iter < self.config.search_time or n_terminals < self.config.min_terminals:\n",
    "            # 1) selection + expansion\n",
    "            v, is_expand = self.root._tree_policy()\n",
    "\n",
    "            # 2) 如果确实扩展了节点，就评估( Evaluation ) + 回溯( Backpropagation )\n",
    "            if is_expand:\n",
    "                reward = 0.0\n",
    "                # 2.1) 根据 value_weight 调用节点的 add_value()\n",
    "                if self.config.value_weight > 0:\n",
    "                    # 例如：对分子做一次价值评估(QED)并加权\n",
    "                    raw_value = v.add_value(is_additional=False)\n",
    "                    reward += self.config.value_weight * raw_value\n",
    "\n",
    "                # # 如果还有额外价值网络 (add_value)，也可以同样加和\n",
    "                # if self.config.add_value_weight > 0:\n",
    "                #     reward += self.config.add_value_weight * v.add_value(is_additional=True)\n",
    "\n",
    "                # 2.2) fast-rollout (simulate)：如果想做“快速模拟”或“快速评估”\n",
    "                if self.config.n_simulations > 0 and self.config.fastrollout_weight > 0:\n",
    "                    if v.is_terminal_node():\n",
    "                        # 如果当前节点已经是终止，就可能直接拿到终止打分\n",
    "                        # (示例) reward += self.config.fastrollout_weight * v.get_final_molecule_outcome()\n",
    "                        raw_value = v.add_value(is_additional=False)\n",
    "                        reward += self.config.fastrollout_weight * raw_value\n",
    "                    else:\n",
    "                        # 否则做一次快速模拟\n",
    "                        raw_value = v.add_simulate()\n",
    "                        reward += self.config.fastrollout_weight * raw_value\n",
    "                        \n",
    "                if reward > 0:\n",
    "                    search_iter += 1\n",
    "                    pbar.update(1)\n",
    "                else:\n",
    "                    unvalid += 1 \n",
    "                        \n",
    "                        \n",
    "                # 缓存这个 reward\n",
    "                v.set_cached_reward(reward)\n",
    "                # 回溯更新\n",
    "                v.backpropagate(reward)\n",
    "\n",
    "                # 打印或日志记录(可选)\n",
    "                # if self.args and self.args.debug_log_level >= 3:\n",
    "                #     print(f\"Rollout: {n_rollouts}, Depth: {v.depth}, Reward: {reward:.2f}\")\n",
    "\n",
    "                # 2.4) 统计计数\n",
    "                # 注意这里 parent_action 是指“从父节点到本节点”的生成内容(可能是SMILES片段)\n",
    "                parent_action = v.parent_action if v.parent_action else \"\"\n",
    "                # 这里示例行数: 用换行来粗略衡量“步骤数量”，可根据需要改成 token 数等\n",
    "                n_action_steps = parent_action.count(13) - 1  # 第一个[SEP]是给定的\n",
    "                n_steps += n_action_steps\n",
    "                n_rollouts += 1\n",
    "                # 如果状态合并时有重复(类似编辑距离或相似度多次重试)，可以记录到n_requests\n",
    "                n_requests += v.n_repeat_by_parent * n_action_steps\n",
    "\n",
    "                if v.is_terminal_node():\n",
    "                    n_terminals += 1\n",
    "                    buffer[v.node_id] = [reward, search_iter]\n",
    "\n",
    "                if search_iter % self.config.freq_log == 0:\n",
    "                    auc_top10 = top_auc(buffer, 10, self.config.freq_log, self.config.search_time)\n",
    "                    auc_top100 = top_auc(buffer, 100, self.config.freq_log, self.config.search_time)\n",
    "                    print(f\"\\niter.{search_iter} AUC for Best 10 Mean: {auc_top10:.4f}\")\n",
    "                    print(f\"iter.{search_iter} AUC for Best 100 Mean: {auc_top100:.4f}\")\n",
    "                    print(f\"unvalid: {unvalid}\")\n",
    "            else:\n",
    "                # 如果没扩展，则说明该节点是之前搜索过的，这次只做回溯\n",
    "                reward = v.get_cached_reward()\n",
    "                v.backpropagate(reward)\n",
    "\n",
    "            # 更新搜索深度\n",
    "            if v.depth > self.max_search_depth:\n",
    "                self.max_search_depth = v.depth\n",
    "\n",
    "        # 关闭进度条\n",
    "        pbar.close()\n",
    "\n",
    "        auc_top10 = top_auc(buffer, 10, self.config.freq_log, self.config.search_time)\n",
    "        auc_top100 = top_auc(buffer, 100, self.config.freq_log, self.config.search_time)\n",
    "        print(f\"\\niter.{search_iter} AUC for Best 10 Mean: {auc_top10:.4f}\")\n",
    "        print(f\"iter.{search_iter} AUC for Best 100 Mean: {auc_top100:.4f}\")\n",
    "\n",
    "        # 更新 MCTS 的累积统计\n",
    "        self.total_rollouts = n_rollouts\n",
    "        self.total_steps = n_steps\n",
    "        self.total_requests = n_requests\n",
    "\n",
    "        self.save_tree('./tree_log/hot_1p5_root.p')\n",
    "        # 使用 'w' 模式写入文件，确保指定编码以支持中文\n",
    "        with open(\"./tree_log/hot_1p5_buffer.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(buffer, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "        return None\n",
    "\n",
    "    def run(self):\n",
    "        start_time = time.time()\n",
    "        self.run_mcts()\n",
    "        end_time = time.time()\n",
    "        self.time_taken = end_time - start_time\n",
    "        print(f\"run_time:{self.time_taken / 60 :.2f}min\")\n",
    "        return None\n",
    "\n",
    "    def get_time(self):\n",
    "        return self.time_taken\n",
    "\n",
    "    def get_max_search_depth(self):\n",
    "        return self.max_search_depth\n",
    "\n",
    "    # 下面这些函数都是原先用于获取终止节点、路径等，如果需要可保留\n",
    "    def get_all_paths(self):\n",
    "        return self.root.generate_all_paths() if self.root else []\n",
    "\n",
    "    def get_final_state_greedy(self):\n",
    "        if not self.root:\n",
    "            return None\n",
    "        greedy_leaf = self.root.best_action_greedy()\n",
    "        return greedy_leaf.get_end_state()\n",
    "\n",
    "    def get_final_state_global(self):\n",
    "        if not self.root:\n",
    "            return None\n",
    "        best_leaf = self.root.best_action_global_leaf()\n",
    "        return best_leaf.get_end_state()\n",
    "\n",
    "    # 如果还需要对树做序列化、保存、加载之类，可保留。也可以去掉\n",
    "    def save_tree(self, filename):\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(self.root, f)\n",
    "\n",
    "    @classmethod\n",
    "    def load_tree(cls, filename, config):\n",
    "        with open(filename, 'rb') as f:\n",
    "            root = pickle.load(f)\n",
    "        # 重建 MCTS\n",
    "        mcts_recover = cls(initial_state=None, config=config)\n",
    "        mcts_recover.root = root\n",
    "        return mcts_recover\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbe173b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:   1%|█▍                                                                                                                                           | 101/10000 [00:48<49:05,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.100 AUC for Best 10 Mean: 0.1128\n",
      "iter.100 AUC for Best 100 Mean: 0.1068\n",
      "unvalid: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:   2%|██▊                                                                                                                                        | 200/10000 [01:28<1:23:07,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.200 AUC for Best 10 Mean: 0.1364\n",
      "iter.200 AUC for Best 100 Mean: 0.1039\n",
      "unvalid: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:   3%|████▏                                                                                                                                        | 300/10000 [02:00<41:06,  3.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.300 AUC for Best 10 Mean: 0.1484\n",
      "iter.300 AUC for Best 100 Mean: 0.1072\n",
      "unvalid: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:   4%|█████▌                                                                                                                                     | 400/10000 [02:29<1:00:08,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.400 AUC for Best 10 Mean: 0.1650\n",
      "iter.400 AUC for Best 100 Mean: 0.1159\n",
      "unvalid: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:   5%|██████▉                                                                                                                                    | 500/10000 [03:04<1:03:36,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.500 AUC for Best 10 Mean: 0.1748\n",
      "iter.500 AUC for Best 100 Mean: 0.1268\n",
      "unvalid: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:   6%|████████▍                                                                                                                                    | 602/10000 [03:37<37:41,  4.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.600 AUC for Best 10 Mean: 0.1763\n",
      "iter.600 AUC for Best 100 Mean: 0.1331\n",
      "unvalid: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:   7%|█████████▊                                                                                                                                   | 700/10000 [04:10<45:32,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.700 AUC for Best 10 Mean: 0.1820\n",
      "iter.700 AUC for Best 100 Mean: 0.1380\n",
      "unvalid: 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:   8%|███████████▎                                                                                                                                 | 801/10000 [04:45<43:15,  3.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.800 AUC for Best 10 Mean: 0.1842\n",
      "iter.800 AUC for Best 100 Mean: 0.1430\n",
      "unvalid: 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:   9%|████████████▌                                                                                                                              | 900/10000 [05:18<1:02:41,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.900 AUC for Best 10 Mean: 0.1843\n",
      "iter.900 AUC for Best 100 Mean: 0.1463\n",
      "unvalid: 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  10%|██████████████                                                                                                                              | 1000/10000 [05:47<44:45,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.1000 AUC for Best 10 Mean: 0.1858\n",
      "iter.1000 AUC for Best 100 Mean: 0.1508\n",
      "unvalid: 54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  11%|███████████████▍                                                                                                                            | 1100/10000 [06:17<37:13,  3.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.1100 AUC for Best 10 Mean: 0.1862\n",
      "iter.1100 AUC for Best 100 Mean: 0.1549\n",
      "unvalid: 54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  12%|████████████████▊                                                                                                                           | 1200/10000 [06:41<29:12,  5.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.1200 AUC for Best 10 Mean: 0.1862\n",
      "iter.1200 AUC for Best 100 Mean: 0.1572\n",
      "unvalid: 56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  13%|██████████████████▏                                                                                                                         | 1301/10000 [07:05<34:01,  4.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.1300 AUC for Best 10 Mean: 0.1862\n",
      "iter.1300 AUC for Best 100 Mean: 0.1597\n",
      "unvalid: 57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  14%|███████████████████▌                                                                                                                        | 1400/10000 [07:29<27:43,  5.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.1400 AUC for Best 10 Mean: 0.1867\n",
      "iter.1400 AUC for Best 100 Mean: 0.1612\n",
      "unvalid: 58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  15%|█████████████████████                                                                                                                       | 1501/10000 [07:54<26:34,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.1500 AUC for Best 10 Mean: 0.1868\n",
      "iter.1500 AUC for Best 100 Mean: 0.1627\n",
      "unvalid: 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  16%|██████████████████████▍                                                                                                                     | 1601/10000 [08:23<42:21,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.1600 AUC for Best 10 Mean: 0.1870\n",
      "iter.1600 AUC for Best 100 Mean: 0.1643\n",
      "unvalid: 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  17%|███████████████████████▊                                                                                                                    | 1699/10000 [08:48<24:09,  5.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.1700 AUC for Best 10 Mean: 0.1882\n",
      "iter.1700 AUC for Best 100 Mean: 0.1658\n",
      "unvalid: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  18%|█████████████████████████▏                                                                                                                  | 1801/10000 [09:14<26:57,  5.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.1800 AUC for Best 10 Mean: 0.1882\n",
      "iter.1800 AUC for Best 100 Mean: 0.1667\n",
      "unvalid: 68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  19%|██████████████████████████▌                                                                                                                 | 1900/10000 [09:39<25:34,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.1900 AUC for Best 10 Mean: 0.1911\n",
      "iter.1900 AUC for Best 100 Mean: 0.1683\n",
      "unvalid: 71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  20%|████████████████████████████                                                                                                                | 2000/10000 [10:09<51:39,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.2000 AUC for Best 10 Mean: 0.1921\n",
      "iter.2000 AUC for Best 100 Mean: 0.1698\n",
      "unvalid: 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  21%|█████████████████████████████▍                                                                                                              | 2100/10000 [10:39<38:24,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.2100 AUC for Best 10 Mean: 0.1921\n",
      "iter.2100 AUC for Best 100 Mean: 0.1704\n",
      "unvalid: 76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  22%|██████████████████████████████▊                                                                                                             | 2200/10000 [11:10<29:58,  4.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.2200 AUC for Best 10 Mean: 0.1921\n",
      "iter.2200 AUC for Best 100 Mean: 0.1709\n",
      "unvalid: 77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  23%|███████████████████████████████▊                                                                                                          | 2301/10000 [11:43<1:25:36,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.2300 AUC for Best 10 Mean: 0.1921\n",
      "iter.2300 AUC for Best 100 Mean: 0.1712\n",
      "unvalid: 81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  24%|█████████████████████████████████▌                                                                                                          | 2400/10000 [12:16<29:05,  4.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.2400 AUC for Best 10 Mean: 0.1921\n",
      "iter.2400 AUC for Best 100 Mean: 0.1719\n",
      "unvalid: 84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  25%|███████████████████████████████████                                                                                                         | 2500/10000 [12:44<26:02,  4.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.2500 AUC for Best 10 Mean: 0.1931\n",
      "iter.2500 AUC for Best 100 Mean: 0.1725\n",
      "unvalid: 84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  26%|████████████████████████████████████▍                                                                                                       | 2601/10000 [13:13<39:23,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.2600 AUC for Best 10 Mean: 0.1943\n",
      "iter.2600 AUC for Best 100 Mean: 0.1732\n",
      "unvalid: 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  27%|█████████████████████████████████████▊                                                                                                      | 2700/10000 [13:50<44:52,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.2700 AUC for Best 10 Mean: 0.1952\n",
      "iter.2700 AUC for Best 100 Mean: 0.1736\n",
      "unvalid: 89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  28%|███████████████████████████████████████▏                                                                                                    | 2801/10000 [14:20<24:30,  4.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.2800 AUC for Best 10 Mean: 0.1952\n",
      "iter.2800 AUC for Best 100 Mean: 0.1737\n",
      "unvalid: 90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  29%|████████████████████████████████████████▋                                                                                                   | 2902/10000 [14:52<22:49,  5.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.2900 AUC for Best 10 Mean: 0.1952\n",
      "iter.2900 AUC for Best 100 Mean: 0.1739\n",
      "unvalid: 91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  30%|██████████████████████████████████████████                                                                                                  | 3000/10000 [15:33<44:08,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.3000 AUC for Best 10 Mean: 0.1969\n",
      "iter.3000 AUC for Best 100 Mean: 0.1744\n",
      "unvalid: 97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  31%|███████████████████████████████████████████▍                                                                                                | 3100/10000 [16:03<19:00,  6.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.3100 AUC for Best 10 Mean: 0.1988\n",
      "iter.3100 AUC for Best 100 Mean: 0.1751\n",
      "unvalid: 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  32%|████████████████████████████████████████████▊                                                                                               | 3199/10000 [16:36<49:13,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.3200 AUC for Best 10 Mean: 0.1988\n",
      "iter.3200 AUC for Best 100 Mean: 0.1755\n",
      "unvalid: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  33%|██████████████████████████████████████████████▏                                                                                             | 3301/10000 [17:10<39:20,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.3300 AUC for Best 10 Mean: 0.1995\n",
      "iter.3300 AUC for Best 100 Mean: 0.1762\n",
      "unvalid: 104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  34%|███████████████████████████████████████████████▌                                                                                            | 3400/10000 [17:42<40:19,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.3400 AUC for Best 10 Mean: 0.1995\n",
      "iter.3400 AUC for Best 100 Mean: 0.1765\n",
      "unvalid: 108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  35%|█████████████████████████████████████████████████                                                                                           | 3501/10000 [18:15<26:04,  4.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.3500 AUC for Best 10 Mean: 0.1995\n",
      "iter.3500 AUC for Best 100 Mean: 0.1769\n",
      "unvalid: 111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  36%|██████████████████████████████████████████████████▍                                                                                         | 3600/10000 [18:54<50:35,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.3600 AUC for Best 10 Mean: 0.1995\n",
      "iter.3600 AUC for Best 100 Mean: 0.1776\n",
      "unvalid: 117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  37%|███████████████████████████████████████████████████▊                                                                                        | 3701/10000 [19:30<32:40,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.3700 AUC for Best 10 Mean: 0.2001\n",
      "iter.3700 AUC for Best 100 Mean: 0.1782\n",
      "unvalid: 121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  38%|█████████████████████████████████████████████████████▏                                                                                      | 3800/10000 [20:06<30:36,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.3800 AUC for Best 10 Mean: 0.2013\n",
      "iter.3800 AUC for Best 100 Mean: 0.1787\n",
      "unvalid: 125\n",
      "\n",
      "iter.3800 AUC for Best 10 Mean: 0.2013\n",
      "iter.3800 AUC for Best 100 Mean: 0.1787\n",
      "unvalid: 126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  39%|██████████████████████████████████████████████████████▌                                                                                     | 3900/10000 [20:43<27:08,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.3900 AUC for Best 10 Mean: 0.2035\n",
      "iter.3900 AUC for Best 100 Mean: 0.1793\n",
      "unvalid: 130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  40%|████████████████████████████████████████████████████████                                                                                    | 4000/10000 [21:16<29:23,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.4000 AUC for Best 10 Mean: 0.2035\n",
      "iter.4000 AUC for Best 100 Mean: 0.1793\n",
      "unvalid: 130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  41%|█████████████████████████████████████████████████████████▍                                                                                  | 4101/10000 [21:53<20:10,  4.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.4100 AUC for Best 10 Mean: 0.2035\n",
      "iter.4100 AUC for Best 100 Mean: 0.1794\n",
      "unvalid: 134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  42%|██████████████████████████████████████████████████████████▊                                                                                 | 4201/10000 [22:36<55:03,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.4200 AUC for Best 10 Mean: 0.2035\n",
      "iter.4200 AUC for Best 100 Mean: 0.1796\n",
      "unvalid: 141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  43%|████████████████████████████████████████████████████████████▏                                                                               | 4300/10000 [23:17<34:17,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.4300 AUC for Best 10 Mean: 0.2040\n",
      "iter.4300 AUC for Best 100 Mean: 0.1800\n",
      "unvalid: 145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  44%|█████████████████████████████████████████████████████████████▌                                                                              | 4400/10000 [23:53<15:06,  6.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.4400 AUC for Best 10 Mean: 0.2040\n",
      "iter.4400 AUC for Best 100 Mean: 0.1800\n",
      "unvalid: 145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  45%|███████████████████████████████████████████████████████████████                                                                             | 4500/10000 [24:33<23:55,  3.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.4500 AUC for Best 10 Mean: 0.2053\n",
      "iter.4500 AUC for Best 100 Mean: 0.1810\n",
      "unvalid: 149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  46%|████████████████████████████████████████████████████████████████▍                                                                           | 4601/10000 [25:05<24:04,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.4600 AUC for Best 10 Mean: 0.2080\n",
      "iter.4600 AUC for Best 100 Mean: 0.1815\n",
      "unvalid: 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  47%|█████████████████████████████████████████████████████████████████▊                                                                          | 4701/10000 [25:44<27:31,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.4700 AUC for Best 10 Mean: 0.2080\n",
      "iter.4700 AUC for Best 100 Mean: 0.1817\n",
      "unvalid: 154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  48%|███████████████████████████████████████████████████████████████████▏                                                                        | 4800/10000 [26:19<41:54,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.4800 AUC for Best 10 Mean: 0.2080\n",
      "iter.4800 AUC for Best 100 Mean: 0.1821\n",
      "unvalid: 154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  49%|████████████████████████████████████████████████████████████████████▌                                                                       | 4900/10000 [26:49<31:56,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.4900 AUC for Best 10 Mean: 0.2080\n",
      "iter.4900 AUC for Best 100 Mean: 0.1821\n",
      "unvalid: 157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  50%|██████████████████████████████████████████████████████████████████████                                                                      | 5000/10000 [27:20<24:00,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.5000 AUC for Best 10 Mean: 0.2080\n",
      "iter.5000 AUC for Best 100 Mean: 0.1825\n",
      "unvalid: 161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  51%|███████████████████████████████████████████████████████████████████████▍                                                                    | 5100/10000 [27:57<26:56,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.5100 AUC for Best 10 Mean: 0.2080\n",
      "iter.5100 AUC for Best 100 Mean: 0.1826\n",
      "unvalid: 166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  52%|████████████████████████████████████████████████████████████████████████▊                                                                   | 5201/10000 [28:29<15:48,  5.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.5200 AUC for Best 10 Mean: 0.2080\n",
      "iter.5200 AUC for Best 100 Mean: 0.1830\n",
      "unvalid: 169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  53%|██████████████████████████████████████████████████████████████████████████▏                                                                 | 5300/10000 [29:02<21:52,  3.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.5300 AUC for Best 10 Mean: 0.2080\n",
      "iter.5300 AUC for Best 100 Mean: 0.1832\n",
      "unvalid: 173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  54%|███████████████████████████████████████████████████████████████████████████▌                                                                | 5400/10000 [29:33<28:06,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.5400 AUC for Best 10 Mean: 0.2080\n",
      "iter.5400 AUC for Best 100 Mean: 0.1833\n",
      "unvalid: 175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  55%|█████████████████████████████████████████████████████████████████████████████                                                               | 5500/10000 [30:05<16:20,  4.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.5500 AUC for Best 10 Mean: 0.2080\n",
      "iter.5500 AUC for Best 100 Mean: 0.1834\n",
      "unvalid: 182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  56%|██████████████████████████████████████████████████████████████████████████████▍                                                             | 5600/10000 [30:41<13:04,  5.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.5600 AUC for Best 10 Mean: 0.2080\n",
      "iter.5600 AUC for Best 100 Mean: 0.1837\n",
      "unvalid: 188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  57%|███████████████████████████████████████████████████████████████████████████████▊                                                            | 5701/10000 [31:14<15:38,  4.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.5700 AUC for Best 10 Mean: 0.2080\n",
      "iter.5700 AUC for Best 100 Mean: 0.1840\n",
      "unvalid: 189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  58%|█████████████████████████████████████████████████████████████████████████████████▏                                                          | 5800/10000 [31:46<33:38,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.5800 AUC for Best 10 Mean: 0.2080\n",
      "iter.5800 AUC for Best 100 Mean: 0.1844\n",
      "unvalid: 193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  59%|██████████████████████████████████████████████████████████████████████████████████▌                                                         | 5900/10000 [32:23<34:14,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.5900 AUC for Best 10 Mean: 0.2080\n",
      "iter.5900 AUC for Best 100 Mean: 0.1845\n",
      "unvalid: 197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  60%|████████████████████████████████████████████████████████████████████████████████████                                                        | 6000/10000 [32:53<19:31,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.6000 AUC for Best 10 Mean: 0.2085\n",
      "iter.6000 AUC for Best 100 Mean: 0.1848\n",
      "unvalid: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  61%|█████████████████████████████████████████████████████████████████████████████████████▍                                                      | 6100/10000 [33:22<20:42,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.6100 AUC for Best 10 Mean: 0.2085\n",
      "iter.6100 AUC for Best 100 Mean: 0.1850\n",
      "unvalid: 203\n",
      "\n",
      "iter.6100 AUC for Best 10 Mean: 0.2085\n",
      "iter.6100 AUC for Best 100 Mean: 0.1850\n",
      "unvalid: 204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  62%|██████████████████████████████████████████████████████████████████████████████████████▊                                                     | 6200/10000 [34:00<18:38,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.6200 AUC for Best 10 Mean: 0.2085\n",
      "iter.6200 AUC for Best 100 Mean: 0.1851\n",
      "unvalid: 206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  63%|████████████████████████████████████████████████████████████████████████████████████████▏                                                   | 6301/10000 [34:32<13:07,  4.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.6300 AUC for Best 10 Mean: 0.2085\n",
      "iter.6300 AUC for Best 100 Mean: 0.1851\n",
      "unvalid: 211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  64%|█████████████████████████████████████████████████████████████████████████████████████████▌                                                  | 6401/10000 [35:12<11:41,  5.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.6400 AUC for Best 10 Mean: 0.2085\n",
      "iter.6400 AUC for Best 100 Mean: 0.1852\n",
      "unvalid: 218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  65%|███████████████████████████████████████████████████████████████████████████████████████████                                                 | 6501/10000 [35:44<12:28,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.6500 AUC for Best 10 Mean: 0.2085\n",
      "iter.6500 AUC for Best 100 Mean: 0.1853\n",
      "unvalid: 223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  66%|████████████████████████████████████████████████████████████████████████████████████████████▍                                               | 6599/10000 [36:16<16:53,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.6600 AUC for Best 10 Mean: 0.2085\n",
      "iter.6600 AUC for Best 100 Mean: 0.1854\n",
      "unvalid: 226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  67%|█████████████████████████████████████████████████████████████████████████████████████████████▊                                              | 6700/10000 [36:54<18:05,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.6700 AUC for Best 10 Mean: 0.2085\n",
      "iter.6700 AUC for Best 100 Mean: 0.1854\n",
      "unvalid: 229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  68%|███████████████████████████████████████████████████████████████████████████████████████████████▏                                            | 6800/10000 [37:27<12:18,  4.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.6800 AUC for Best 10 Mean: 0.2085\n",
      "iter.6800 AUC for Best 100 Mean: 0.1855\n",
      "unvalid: 230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  69%|████████████████████████████████████████████████████████████████████████████████████████████████▌                                           | 6899/10000 [38:00<16:41,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.6900 AUC for Best 10 Mean: 0.2085\n",
      "iter.6900 AUC for Best 100 Mean: 0.1855\n",
      "unvalid: 232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  70%|██████████████████████████████████████████████████████████████████████████████████████████████████                                          | 7000/10000 [38:30<18:50,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.7000 AUC for Best 10 Mean: 0.2085\n",
      "iter.7000 AUC for Best 100 Mean: 0.1856\n",
      "unvalid: 236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  71%|███████████████████████████████████████████████████████████████████████████████████████████████████▍                                        | 7100/10000 [39:09<08:31,  5.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.7100 AUC for Best 10 Mean: 0.2085\n",
      "iter.7100 AUC for Best 100 Mean: 0.1857\n",
      "unvalid: 239\n",
      "\n",
      "iter.7100 AUC for Best 10 Mean: 0.2085\n",
      "iter.7100 AUC for Best 100 Mean: 0.1857\n",
      "unvalid: 240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  72%|████████████████████████████████████████████████████████████████████████████████████████████████████▊                                       | 7200/10000 [39:44<12:56,  3.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.7200 AUC for Best 10 Mean: 0.2085\n",
      "iter.7200 AUC for Best 100 Mean: 0.1858\n",
      "unvalid: 243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  73%|██████████████████████████████████████████████████████████████████████████████████████████████████████▏                                     | 7299/10000 [40:12<08:11,  5.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.7300 AUC for Best 10 Mean: 0.2085\n",
      "iter.7300 AUC for Best 100 Mean: 0.1860\n",
      "unvalid: 243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  74%|███████████████████████████████████████████████████████████████████████████████████████████████████████▌                                    | 7401/10000 [40:42<09:27,  4.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.7400 AUC for Best 10 Mean: 0.2085\n",
      "iter.7400 AUC for Best 100 Mean: 0.1860\n",
      "unvalid: 244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████                                   | 7500/10000 [41:16<16:56,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.7500 AUC for Best 10 Mean: 0.2085\n",
      "iter.7500 AUC for Best 100 Mean: 0.1860\n",
      "unvalid: 248\n",
      "\n",
      "iter.7500 AUC for Best 10 Mean: 0.2085\n",
      "iter.7500 AUC for Best 100 Mean: 0.1860\n",
      "unvalid: 249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  76%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                 | 7600/10000 [41:53<14:56,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.7600 AUC for Best 10 Mean: 0.2085\n",
      "iter.7600 AUC for Best 100 Mean: 0.1862\n",
      "unvalid: 255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  77%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                | 7700/10000 [42:32<13:38,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.7700 AUC for Best 10 Mean: 0.2085\n",
      "iter.7700 AUC for Best 100 Mean: 0.1864\n",
      "unvalid: 262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  78%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                              | 7800/10000 [43:04<08:00,  4.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.7800 AUC for Best 10 Mean: 0.2090\n",
      "iter.7800 AUC for Best 100 Mean: 0.1866\n",
      "unvalid: 266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  79%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                             | 7900/10000 [43:42<25:59,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter.7900 AUC for Best 10 Mean: 0.2090\n",
      "iter.7900 AUC for Best 100 Mean: 0.1866\n",
      "unvalid: 269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS simulations:  79%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                             | 7914/10000 [43:50<17:38,  1.97it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 71\u001b[0m\n\u001b[1;32m     67\u001b[0m seed \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m42\u001b[39m\n\u001b[1;32m     68\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 71\u001b[0m \u001b[43mmain_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 54\u001b[0m, in \u001b[0;36mmain_test\u001b[0;34m(seed, device)\u001b[0m\n\u001b[1;32m     52\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(checkpoint)\n\u001b[1;32m     53\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 54\u001b[0m \u001b[43mTest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     56\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m-\u001b[39m start_time\n",
      "Cell \u001b[0;32mIn[2], line 32\u001b[0m, in \u001b[0;36mTest\u001b[0;34m(model, tokenizer, device, output_file_path)\u001b[0m\n\u001b[1;32m     30\u001b[0m mcts \u001b[38;5;241m=\u001b[39m MCTS(initial_state, mcts_config)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 32\u001b[0m     \u001b[43mmcts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 908\u001b[0m, in \u001b[0;36mMCTS.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    907\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 908\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_mcts\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    909\u001b[0m     end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    910\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_taken \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m-\u001b[39m start_time\n",
      "Cell \u001b[0;32mIn[1], line 838\u001b[0m, in \u001b[0;36mMCTS.run_mcts\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    835\u001b[0m         reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mfastrollout_weight \u001b[38;5;241m*\u001b[39m raw_value\n\u001b[1;32m    836\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    837\u001b[0m         \u001b[38;5;66;03m# 否则做一次快速模拟\u001b[39;00m\n\u001b[0;32m--> 838\u001b[0m         raw_value \u001b[38;5;241m=\u001b[39m \u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_simulate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    839\u001b[0m         reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mfastrollout_weight \u001b[38;5;241m*\u001b[39m raw_value\n\u001b[1;32m    841\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reward \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[0;32mIn[1], line 640\u001b[0m, in \u001b[0;36mMonteCarloTreeSearchNode.add_simulate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21madd_simulate\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    632\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;124;03m    做一个“快速模拟/评估”。\u001b[39;00m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;124;03m    在分子GPT场景下，可以:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;124;03m    这样让节点在还未真正完全展开时，就对可能的后续做一个估计，用于指导MCTS。\u001b[39;00m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 640\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfast_rollout_evaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    642\u001b[0m     \u001b[38;5;66;03m# 此处示例返回平均值\u001b[39;00m\n\u001b[1;32m    643\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "Cell \u001b[0;32mIn[1], line 650\u001b[0m, in \u001b[0;36mMonteCarloTreeSearchNode.fast_rollout_evaluation\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    645\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfast_rollout_evaluation\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    646\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    647\u001b[0m \u001b[38;5;124;03m    Fast-rollout and return mean value from ORM.\u001b[39;00m\n\u001b[1;32m    648\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 650\u001b[0m     action, smiles_answer, has_end_token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_fragment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcur_molecule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcur_molecule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    652\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_seq_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    654\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    655\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    657\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkv_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_simulation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m    659\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    660\u001b[0m     _, smiles \u001b[38;5;241m=\u001b[39m sentence2mol(smiles_answer)\n\u001b[1;32m    661\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mget_reward(smiles)\n",
      "Cell \u001b[0;32mIn[1], line 332\u001b[0m, in \u001b[0;36mMolecularProblemState.generate_fragment\u001b[0;34m(self, cur_molecule, max_seq_len, temperature, top_k, stream, rp, kv_cache, is_simulation)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;66;03m# print('[A]: ', end='')\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 332\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mres_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    334\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo answer\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/fragpt/lib/python3.9/site-packages/torch/utils/_contextlib.py:36\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m---> 36\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     40\u001b[0m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[0;32m/data1/yzf/fragment_GPT/model.py:224\u001b[0m, in \u001b[0;36mGPT.generate\u001b[0;34m(self, idx, tokenizer, max_new_tokens, temperature, top_k, stream, rp, kv_cache, is_simulation)\u001b[0m\n\u001b[1;32m    222\u001b[0m     inference_res, init_inference \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(idx, tokenizer, kv_cache\u001b[38;5;241m=\u001b[39mkv_cache), \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 224\u001b[0m     inference_res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkv_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkv_cache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m logits, _, _ \u001b[38;5;241m=\u001b[39m inference_res\n\u001b[1;32m    227\u001b[0m logits \u001b[38;5;241m=\u001b[39m logits[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\n",
      "File \u001b[0;32m~/anaconda3/envs/fragpt/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/fragpt/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/data1/yzf/fragment_GPT/model.py:202\u001b[0m, in \u001b[0;36mGPT.forward\u001b[0;34m(self, idx, tokenizer, targets, kv_cache, current_idx)\u001b[0m\n\u001b[1;32m    199\u001b[0m attn_maps \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[0;32m--> 202\u001b[0m     x, attn \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkv_cache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_idx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# transformer * 8\u001b[39;00m\n\u001b[1;32m    203\u001b[0m     attn_maps\u001b[38;5;241m.\u001b[39mappend(attn)\n\u001b[1;32m    205\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_f(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/fragpt/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/fragpt/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/data1/yzf/fragment_GPT/model.py:113\u001b[0m, in \u001b[0;36mBlock.forward\u001b[0;34m(self, x, kv_cache, current_idx)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, kv_cache\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, current_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 113\u001b[0m     y, attn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkv_cache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m y\n\u001b[1;32m    115\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln2(x))\n",
      "File \u001b[0;32m~/anaconda3/envs/fragpt/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/fragpt/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/data1/yzf/fragment_GPT/model.py:83\u001b[0m, in \u001b[0;36mCausalSelfAttention.forward\u001b[0;34m(self, x, kv_cache, current_idx)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_cache, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_cache \u001b[38;5;241m=\u001b[39m k, v\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# causal self-attention; Self-attend: (B, nh, T, hs) x (B, nh, hs, T) -> (B, nh, T, T)\u001b[39;00m\n\u001b[0;32m---> 83\u001b[0m att \u001b[38;5;241m=\u001b[39m (\u001b[43mq\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m) \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(k\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)))\n\u001b[1;32m     84\u001b[0m mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtril(torch\u001b[38;5;241m.\u001b[39mones(T, T, device\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mdevice))\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, T, T)  \u001b[38;5;66;03m# 下三角矩阵\u001b[39;00m\n\u001b[1;32m     85\u001b[0m att \u001b[38;5;241m=\u001b[39m att\u001b[38;5;241m.\u001b[39mmasked_fill(mask[:, :, :T, :T] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-inf\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from utils.train_utils import seed_all\n",
    "import os\n",
    "from tokenizer import SmilesTokenizer\n",
    "from model import GPTConfig, GPT\n",
    "import time\n",
    "from utils.chem_utils import sentence2mol\n",
    "from rdkit import rdBase\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 禁用所有日志信息\n",
    "rdBase.DisableLog('rdApp.warning')\n",
    "\n",
    "\n",
    "def Test(model, tokenizer, device, output_file_path):\n",
    "    model.eval()\n",
    "    predictor = 'Troglitazone_Rediscovery'\n",
    "    results = []\n",
    "    # 找到第一个分隔符\n",
    "    # indices = torch.nonzero(x.squeeze(0) == 13, as_tuple=True)[0]\n",
    "    # first_index = indices[0].item()\n",
    "    # x = x[:, :first_index + 1]   # 取第一个片段作为输入\n",
    "    x = torch.tensor([1], dtype=torch.int64).unsqueeze(0)\n",
    "    x = x.to(device)\n",
    "    for i in range(1):\n",
    "        print('sample:', i+1)\n",
    "        initial_state = MolecularProblemState(model, tokenizer, predictor, x)\n",
    "        mcts_config = MCTSConfig()\n",
    "        mcts = MCTS(initial_state, mcts_config)\n",
    "        with torch.no_grad():\n",
    "            mcts.run()\n",
    "\n",
    "\n",
    "def main_test(seed, device):\n",
    "    # 设置随机种子的值\n",
    "    seed_value = int(seed)\n",
    "    seed_all(seed_value)\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = device\n",
    "    device = torch.device(f'cuda:{0}')  # 逻辑编号 cuda:0 对应 os.environ[\"CUDA_VISIBLE_DEVICES\"]中的第一个gpu\n",
    "\n",
    "    tokenizer = SmilesTokenizer('./vocabs/vocab.txt')\n",
    "    tokenizer.bos_token = \"[BOS]\"\n",
    "    tokenizer.bos_token_id = tokenizer.convert_tokens_to_ids(\"[BOS]\")\n",
    "    tokenizer.eos_token = \"[EOS]\"\n",
    "    tokenizer.eos_token_id = tokenizer.convert_tokens_to_ids(\"[EOS]\")\n",
    "\n",
    "    mconf = GPTConfig(vocab_size=tokenizer.vocab_size, n_layer=12, n_head=12, n_embd=768)\n",
    "    model = GPT(mconf).to(device)\n",
    "    checkpoint = torch.load(f'./weights/fragpt.pt', weights_only=True)\n",
    "\n",
    "    model.load_state_dict(checkpoint)\n",
    "    start_time = time.time()\n",
    "    Test(model, tokenizer, device, output_file_path='')\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    print(f\"运行时间: {elapsed_time:.4f} 秒\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \"\"\"\n",
    "        world_size: 所有的进程数量\n",
    "        rank: 全局的进程id\n",
    "    \"\"\"\n",
    "    \n",
    "    seed = 42\n",
    "    device = '2'\n",
    "    \n",
    "    \n",
    "    main_test(seed, device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2961b4cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fragpt",
   "language": "python",
   "name": "fragpt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
